Thiết kế memory là chìa khoá của thiết kế hệ thống. Hệ thống memory trên chip thường là phần đắt nhất và quyết định đến performance của hệ thống nhiều nhất.
Trong 1 hệ thống SoC có 3 yếu tố quyết định đến hiệu suất của hệ thống đó là:
Memory 
Bộ vi xử lí (processors)
Bus (interconnection) và IO.
Trong đó Memory đóng vai trò cực kì quan trọng và là thành phần quan trọng nhất trong việc quyết định performance của chip SoC.
Để thiết kế memory cho 1 chip cụ thể ta cần cân nhắc các yếu tố sau: 
Hệ điều hành.
Kích thước.
Tính biến đổi của quy trình ứng dụng.
Điều này quyết định quan trọng đến kích thước của memory và cách thức thiết kế memory thực hay ảo.
bộ nhớ cache, bộ nhớ truy cập nhanh Một vùng đặc biệt của các chip nhớ tốc độ nhanh, được dành riêng để lưu giữ các thông tin thường xuyên được truy xuất từ RAM ra nhất. Đồng nghĩa với cache ngoài ( external cache). Bộ nhớ cache thường là một đoạn nhỏ ( 32 K đến 512 K) của các chip RAM tĩnh tốc độ rất nhanh ( SRAM) cùng với bus riêng của nó nối với đơn vị xử lý trung tâm ( CPU), và thường được dùng để lưu giữ dữ liệu và mã lệnh mà CPU hay đòi hỏi đến. Khi CPU đòi hỏi dùng lại dữ liệu này, nó sẽ được cung cấp ngay theo đúng tốc độ hoạt động của bộ vi xử lý. Vì cache giao thiệp trực tiếp với CPU, nên bus có thể dùng loại rộng để nâng cao hơn nữa hiệu suất của bộ nhớ. Bộ nhớ cache khác với cache phần mềm; đó là khu vực của bộ RAM bình thường, được dành riêng để lưu giữ những thông tin thường được lấy từ các ổ đĩa ra.
Chúng ta có sự đánh đổi (trade-off) giữa 3 yếu tố: vi xử lí, bus và memory vì vậy trong bài này tôi sẽ xem xét các thành phần khác là lý tưởng để tập trung giải quyết và so sánh các vấn đề liên quan đến memory.
1.	Bộ nhớ ngoài SoC: flash.
Công nghệ Flash là một công nghệ phát triển nhanh với những cải tiến được công bố một cách thường xuyên. Flash không thể thay thế bộ nhớ một cách hoàn toàn nhưng có thể được xem như là một sự thay thế đĩa. Tuy nhiên, trong một số trường hợp và các điều kiện, nó có thể phục vụ mục đích kép của bộ nhớ và lưu trữ sao lưu không biến đổi. Bộ nhớ flash bao gồm một loạt các bóng bán dẫn cổng. Các bóng bán dẫn này tương tự như các bóng bán dẫn MOS nhưng có cấu trúc hai cổng: cổng điều khiển và cổng kết nối cách điện. Phí được lưu trữ trên cổng ating oating bị mắc kẹt ở đó, cung cấp lưu trữ không dễ bay hơi. Trong khi dữ liệu có thể được viết lại, công nghệ hiện tại có số lượng hạn chế các chu kỳ viết lại đáng tin cậy, thường là dưới một triệu. Vì sự xuống cấp khi sử dụng có thể là một vấn đề, việc phát hiện và sửa lỗi thường xuyên được thực hiện. Mặc dù mật độ là tuyệt vời cho các thiết bị bán dẫn, nhưng giới hạn chu kỳ ghi thường hạn chế việc sử dụng để lưu trữ dữ liệu không thường xuyên, chẳng hạn như các chương trình và các tệp lớn. Có hai loại triển khai ﬂ tro: NOR và NAND. Việc triển khai NOR là rõ ràng hơn, nhưng NAND cung cấp mật độ bit tốt hơn đáng kể. Cũng có thể triển khai lai NOR / NAND với mảng NOR đóng vai trò là bộ đệm cho mảng NAND lớn hơn. Bảng 4.3 cung cấp so sánh các triển khai này. Thẻ nhớ flash có nhiều định dạng khác nhau; kích thước lớn hơn thường cũ hơn (xem Bảng 4.2). Xúc xắc tro nhỏ có thể được xếp chồng lên nhau với chip SOC để trình bày một gói hệ thống / bộ nhớ duy nhất. Một tro cũng có thể được xếp chồng lên nhau để tạo ra các gói bộ nhớ đơn lớn (64 Điều 2 56 G B). Trong công nghệ hiện tại, ﬂ tro thường được tìm thấy trong các triển khai chết. Tuy nhiên, có một số biến thể tro được thiết kế đặc biệt để tương thích với công nghệ SOC thông thường. SONOS [201] là một ví dụ không biến đổi và Z - RAM [91] là một ví dụ thay thế DRAM. Cả hai dường như không bị hạn chế viết lại chu kỳ. Z - RAM dường như tương thích với tốc độ DRAM trong khi cung cấp mật độ được cải thiện. SONOS cung cấp mật độ nhưng với thời gian truy cập chậm hơn eDRAM.

Yếu tố quan trọng và rõ ràng nhất trong thiết kế hệ thống bộ nhớ là vị trí của bộ nhớ chính. Có hai vị trí mà bộ nhớ chính được đặt đó là on-die (cùng die với bộ xử lý) hoặc off-die (trên die của chính nó hoặc trên một mô-đun có nhiều die mà không trùng với die của bộ xử lí).
Thiết kế của hệ thống bộ nhớ bị giới hạn bởi hai tham số cơ bản xác định hiệu năng của hệ thống bộ nhớ. Đầu tiên là thời gian truy cập.
Đây là thời gian để bộ xử lý gửi một request đến hệ thống bộ nhớ, truy cập dữ liệu và trả dữ liệu lại cho bộ xử lý. Thời gian truy cập được quyết định bởi các tham số vật lý của hệ thống bộ nhớ - khoảng cách giữa bộ xử lý và hệ thống bộ nhớ, hoặc độ trễ bus, độ trễ chip, v.v. Tham số thứ hai là băng thông bộ nhớ. Đó là khả năng của bộ nhớ để đáp ứng lại các yêu cầu trên mỗi đơn vị thời gian. Băng thông chủ yếu được xác định theo cách tổ chức hệ thống bộ nhớ vật lý - số lượng mảng bộ nhớ độc lập và sử dụng các chế độ truy cập tuần tự đặc biệt. Hệ thống bộ đệm phải bù cho các giới hạn về thời gian truy cập bộ nhớ và băng thông.
Bộ xử lý máy trạm, nhắm mục tiêu hiệu năng cao, đòi hỏi một hệ thống bộ nhớ rất hiệu quả, một nhiệm vụ gây khó khăn cho việc sắp xếp bộ nhớ.
Thiết kế bộ nhớ dựa trên máy trạm và bảng mạch rõ ràng là một thách thức lớn hơn đối với các nhà thiết kế. Phải đặc biệt chú ý đến bộ đệm, phải bù cho những khó khăn về vị trí bộ nhớ.
Kích thước của bộ nhớ.

Vì nó sẽ trở nên rõ ràng trong chương này, thiết kế cho bộ nhớ lớn là vấn đề chính trong thiết kế bo mạch hệ thống. Vậy tại sao không giới hạn bộ nhớ ở các kích thước có thể được kết hợp trên một khuôn? Trong một hệ thống bộ nhớ ảo, chúng ta vẫn có thể truy cập các không gian địa chỉ lớn cho các ứng dụng. Đối với các máy trạm, môi trường ứng dụng (được đại diện bởi hệ điều hành) đã tăng lên đáng kể (xem Hình 4.3). Khi môi trường tiếp tục phát triển, tập làm việc hoặc các trang lưu trữ đang hoạt động cũng vậy. Điều này đòi hỏi bộ nhớ thực (vật lý) nhiều hơn để chứa đủ số lượng trang để tránh hoán đổi trang quá mức, có thể phá hủy hiệu suất. Các hệ thống dựa trên bảng phải đối mặt với một vấn đề hơi khác nhau. Ở đây, các bộ dữ liệu dựa trên phương tiện tự nhiên rất lớn và yêu cầu băng thông lớn từ bộ nhớ và khả năng xử lý đáng kể từ bộ xử lý phương tiện. Tuy nhiên, các hệ thống dựa trên bảng có một lợi thế, vì thời gian truy cập hiếm khi là một vấn đề miễn là các yêu cầu về băng thông được đáp ứng. Bao nhiêu bộ nhớ chúng ta có thể đặt trên một cái chết? Vâng, điều đó phụ thuộc vào công nghệ (kích thước tính năng) và hiệu suất cần thiết. Bảng 4.1 cho thấy diện tích chiếm dụng cho các công nghệ khác nhau. Kích thước eDRAM giả định bộ nhớ tương đối lớn
mảng (xem sau trong chương này). Vì vậy, ví dụ, trong công nghệ 45nm, chúng ta có thể mong đợi có khoảng 49,2 kA / cm 2 hoặc khoảng 8 MB eDRAM. Tiến bộ thiết kế


Bộ nhớ nhỏ hầu như luôn luôn nhanh hơn bộ nhớ lớn hơn, vì vậy rất hữu ích khi lưu trữ các tập lệnh và dữ liệu thường xuyên được sử dụng (hoặc dự đoán) trong một bộ nhớ nhỏ, dễ truy cập (truy cập một chu kỳ). Nếu bộ nhớ này được lập trình viên quản lý trực tiếp, nó được gọi là bộ nhớ Scratchpad; nếu nó được quản lý bởi phần cứng, nó được gọi là bộ đệm. Vì quản lý là một quá trình rườm rà, hầu hết các máy tính có mục đích chung chỉ sử dụng bộ nhớ đệm. SOC, tuy nhiên, cung cấp tiềm năng của việc thay thế Scratchpad. Giả sử rằng ứng dụng này đã nổi tiếng, lập trình viên có thể kiểm soát rõ ràng việc truyền dữ liệu theo dự đoán sử dụng. Loại bỏ phần cứng kiểm soát bộ đệm cung cấp thêm diện tích cho kích thước bàn phím lớn hơn, một lần nữa cải thiện hiệu suất. SOC thực hiện Scratchpad thường cho dữ liệu chứ không phải cho hướng dẫn, vì bộ đệm đơn giản hoạt động tốt cho hướng dẫn. Hơn nữa, nó không đáng để nỗ lực lập trình để trực tiếp quản lý chuyển lệnh. Phần còn lại của phần này xử lý lý thuyết và kinh nghiệm về bộ nhớ đệm. Bởi vì đã có quá nhiều bài viết về bộ nhớ cache, thật dễ dàng để quên cách tiếp cận Scratchpad đơn giản và cũ hơn, nhưng với SOC, đôi khi cách tiếp cận đơn giản là tốt nhất. Bộ nhớ cache hoạt động trên cơ sở địa phương của hành vi chương trình [113]. Có ba nguyên tắc liên quan:
   1. Địa phương không gian. Được cấp quyền truy cập vào một vị trí cụ thể trong bộ nhớ, có khả năng cao là các quyền truy cập khác sẽ được thực hiện cho vị trí đó hoặc các vị trí lân cận trong vòng đời của chương trình.
2. Địa phương tạm thời. Đưa ra một chuỗi các tham chiếu đến n vị trí, sẽ có các tham chiếu vào cùng các vị trí có xác suất cao.
 3. Tính tuần tự. Cho rằng một tham chiếu đã được thực hiện cho vị trí s, có thể trong một vài tham chiếu tiếp theo, sẽ có một tham chiếu đến vị trí của s + 1. Đây là một trường hợp đặc biệt của địa phương không gian.
Người thiết kế bộ đệm phải giải quyết các yêu cầu truy cập của bộ xử lý một mặt và mặt khác là các yêu cầu của hệ thống bộ nhớ. Thiết kế bộ đệm hiệu quả cân bằng những điều này trong các hạn chế chi phí.


DỮ LIỆU
Kích thước bộ đệm phần lớn xác định hiệu suất bộ đệm (tỷ lệ bỏ lỡ). Bộ nhớ cache càng lớn, tỷ lệ bỏ lỡ càng thấp. Hầu như tất cả dữ liệu tỷ lệ bỏ lỡ bộ nhớ cache là theo kinh nghiệm và, do đó, có những hạn chế nhất định. Dữ liệu bộ nhớ cache phụ thuộc mạnh vào chương trình. Ngoài ra, dữ liệu thường được dựa trên các máy cũ hơn, trong đó bộ nhớ và kích thước chương trình được chia nhỏ và nhỏ. Dữ liệu này cho thấy tỷ lệ bỏ lỡ thấp đối với bộ đệm kích thước tương đối nhỏ. Do đó, có xu hướng tỷ lệ bỏ lỡ đo được của một kích thước bộ đệm cụ thể sẽ tăng theo thời gian. Đây chỉ đơn giản là kết quả của các phép đo được thực hiện trên các chương trình có kích thước tăng dần. Cách đây một thời gian, Smith [224] đã phát triển một loạt các tỷ lệ bỏ lỡ mục tiêu thiết kế (DTMR) đại diện cho ước tính về những gì một nhà thiết kế có thể mong đợi từ bộ đệm (hướng dẫn và dữ liệu) tích hợp. Các dữ liệu này được trình bày trong Hình 4 .9 và đưa ra ý tưởng về tỷ lệ bỏ lỡ điển hình như là một hàm của bộ đệm và kích thước dòng. Đối với kích thước bộ đệm lớn hơn 1 MB, một quy tắc chung là nhân đôi kích thước bằng một nửa tỷ lệ bỏ lỡ. Quy tắc chung là ít hợp lệ trong các chương trình dựa trên giao dịch.



 4.7 CHÍNH SÁCH VIẾT
 Làm thế nào là bộ nhớ được cập nhật trên một ghi? Người ta có thể ghi vào cả bộ đệm và bộ nhớ (ghi - qua hoặc WT) hoặc chỉ ghi vào bộ đệm (sao chép - quay lại hoặc CB - đôi khi được gọi là ghi lại), cập nhật bộ nhớ khi thay thế dòng. Hai chiến lược này là các chính sách ghi bộ đệm cơ bản (Hình 4 .10). Bộ đệm ghi thông qua (Hình 4.10 a) lưu trữ vào cả bộ nhớ cache và bộ nhớ chính trên mỗi bộ lưu trữ CPU. Ưu điểm: Điều này giữ lại hình ảnh nhất quán (cập nhật) của hoạt động chương trình trong bộ nhớ. Nhược điểm: Băng thông bộ nhớ có thể cao bị chi phối bởi lưu lượng ghi. Trong bộ đệm sao chép lại (Hình 4 .10b), dữ liệu mới được ghi vào bộ nhớ khi dòng được thay thế. Điều này đòi hỏi phải theo dõi các dòng sửa đổi (hoặc bẩn bẩn), nhưng dẫn đến giảm bộ nhớ cho việc ghi:
1. Bit bẩn được thiết lập nếu một ghi xảy ra bất cứ nơi nào trong dòng.
2. Từ các dấu vết khác nhau [223], xác suất để một dòng được thay thế bị bẩn là trung bình 47% (dao động từ 22% đến 80%).
 3. Quy tắc ngón tay cái: Một nửa số dòng dữ liệu được thay thế là bẩn. Vì vậy, đối với bộ đệm dữ liệu, giả sử 50% là dòng bẩn và đối với bộ đệm tích hợp, giả sử 30% là dòng bẩn.
 Hầu hết các bộ nhớ cache lớn hơn sử dụng bản sao - trở lại; ghi - thông thường được giới hạn trong các bộ đệm nhỏ hoặc bộ nhớ chuyên dụng cung cấp hình ảnh cập nhật của bộ nhớ. Cuối cùng, chúng ta nên làm gì khi một lệnh ghi (hoặc lưu trữ) bị mất trong bộ đệm? Chúng ta có thể tìm nạp dòng đó từ bộ nhớ (phân bổ ghi hoặc WA) hoặc chỉ ghi vào bộ nhớ (không phân bổ ghi hoặc NWA). Hầu hết các bộ đệm thông tin không phân bổ trên ghi (WTNWA) và hầu hết các bộ đệm sao chép lại phân bổ (CBWA).

Điều gì xảy ra trên một bộ nhớ cache bỏ lỡ? Nếu không tìm thấy địa chỉ tham chiếu trong thư mục, sẽ xảy ra lỗi bộ nhớ cache. Phải nhanh chóng thực hiện hai hành động: (1) Dòng bị bỏ lỡ phải được lấy từ bộ nhớ chính và (2) một trong các dòng bộ đệm hiện tại phải được chỉ định để thay thế bởi dòng hiện đang truy cập (dòng bị bỏ lỡ).
    4.8.1 Tìm nạp một dòng 
Trong bộ đệm ghi thông qua, tìm nạp một dòng liên quan đến việc truy cập vào dòng bị bỏ lỡ và dòng được thay thế là

4.8.2 Thay thế dòng
Chính sách thay thế chọn một dòng để thay thế khi bộ đệm đầy. Có ba chính sách thay thế được sử dụng rộng rãi:
   1. Ít nhất được sử dụng gần đây (LRU). Dòng được truy cập gần đây nhất (bằng cách đọc hoặc ghi) được thay thế. 2. Đầu vào - Đầu ra (FIFO). Dòng đã ở trong bộ đệm lâu nhất được thay thế. 3. Thay thế ngẫu nhiên (RAND). Thay thế được xác định ngẫu nhiên.
 Do chính sách của LRU tương ứng với khái niệm về địa phương tạm thời, nên nhìn chung chính sách này được ưu tiên. Nó cũng là phức tạp nhất để thực hiện. Mỗi dòng có một bộ đếm được cập nhật trên một lần đọc (hoặc viết). Vì các bộ đếm này có thể lớn, nên thường tạo ra một xấp xỉ với LRU thực với các bộ đếm nhỏ hơn.
c04.indd 136 c04.indd 136 5/4/2011 9:54:14 AM 5/4/2011 9:54:14 AM
CHIẾN LƯỢC ĐỂ THAY THẾ LINE TRONG THỜI GIAN 137
 Mặc dù LRU hoạt động tốt hơn cả FIFO hoặc RAND, nhưng việc sử dụng RAND hoặc FIFO đơn giản hơn chỉ khuếch đại tỷ lệ bỏ lỡ LRU (DTMR) khoảng 1,10 (tức là, 10%) [223].
 



4.9 CÁC LOẠI CACHE KHÁC
  Cho đến nay, chúng tôi chỉ xem xét bộ đệm tích hợp đơn giản (còn được gọi là bộ đệm cache của uni ﬁ ed), chứa cả dữ liệu và hướng dẫn. Trong một số phần tiếp theo, chúng tôi xem xét các loại bộ đệm khác nhau. Danh sách chúng tôi trình bày (Bảng 4.5) hầu như không đầy đủ, nhưng nó minh họa một số thiết kế bộ đệm khác nhau có thể cho các ứng dụng đặc biệt hoặc thậm chí phổ biến. Hầu hết các bộ vi xử lý hiện có sử dụng các phân tách I và D đau, được mô tả trong phần tiếp theo.

4.11.1 Giới hạn về Kích thước Mảng Cache
 Cache bao gồm một mảng RAM tĩnh (SRAM) của các ô lưu trữ. Khi mảng tăng kích thước, đã làm tăng chiều dài của dây cần thiết để truy cập vào ô từ xa nhất của nó. Điều này chuyển thành độ trễ truy cập bộ nhớ đệm. McFarland [166] đã mô hình hóa độ trễ và thấy rằng một xấp xỉ có thể được biểu diễn dưới dạng thời gian truy cập :

 
Trong đó f là kích thước tính năng tính bằng micron, C là dung lượng mảng bộ nhớ cache tính bằng kilobyte và A là mức độ kết hợp (trong đó ánh xạ trực tiếp = 1).
Hiệu quả của phương trình này (cho A = 1) có thể được nhìn thấy trong Hình 4.13. Nếu chúng tôi giới hạn thời gian truy cập cấp 1 dưới 1 ns, có lẽ chúng tôi bị giới hạn ở một mảng bộ đệm khoảng 32 KB. Trong khi có thể xen kẽ nhiều mảng, bản thân xen kẽ có một chi phí chung. Vì vậy, thông thường, bộ nhớ cache L1 nhỏ hơn 64 KB; Bộ nhớ cache L2 thường nhỏ hơn 512 KB (có thể được xen kẽ bằng cách sử dụng các mảng nhỏ hơn); và bộ đệm L3 sử dụng nhiều mảng từ 256 K B trở lên để tạo bộ đệm lớn, thường bị giới hạn bởi kích thước khuôn.

4.11.2 Đánh giá bộ nhớ cache đa cấp
 Trong trường hợp bộ đệm đa cấp, chúng ta có thể đánh giá hiệu suất của cả hai cấp bằng cách sử dụng dữ liệu bộ đệm L1. Một hệ thống bộ đệm hai cấp được gọi là bao gồm nếu tất cả nội dung của bộ đệm cấp thấp hơn (L1) cũng được chứa trong bộ đệm cấp cao hơn (L2). Phân tích bộ đệm cấp hai được thực hiện bằng cách sử dụng nguyên tắc đưa vào; nghĩa là, bộ đệm lớn, cấp hai bao gồm các dòng giống như trong bộ đệm cấp thứ nhất. Do đó, với mục đích đánh giá hiệu năng, chúng ta có thể giả sử rằng bộ đệm cấp đầu tiên không tồn tại. Tổng số lỗi xảy ra trong bộ đệm cấp hai có thể được xác định bằng cách giả sử rằng bộ xử lý đã thực hiện tất cả các yêu cầu của nó tới bộ đệm cấp hai mà không có bộ đệm cấp thứ nhất. Có những cân nhắc về thiết kế trong việc cung cấp bộ đệm cấp hai cho bộ đệm cấp thứ nhất hiện có. Kích thước dòng của bộ đệm cấp hai phải bằng hoặc lớn hơn bộ đệm cấp thứ nhất. Mặt khác, nếu kích thước dòng trong bộ đệm cấp hai nhỏ hơn, việc tải dòng trong bộ đệm cấp thứ nhất sẽ chỉ gây ra hai lỗi trong bộ đệm cấp hai. Hơn nữa, bộ đệm cấp hai phải lớn hơn đáng kể so với cấp đầu tiên; nếu không, nó sẽ không có lợi ích.
Trong một hệ thống hai cấp độ, như trong Hình 4.14, với bộ đệm cấp độ đầu tiên, L1 và bộ đệm cấp hai, L2, chúng tôi định nghĩa các tỷ lệ bỏ lỡ sau [202]:
   1. Tỷ lệ bỏ lỡ cục bộ đơn giản là số lần bỏ lỡ do bộ đệm chia cho số lượng tham chiếu đến nó. Đây là cách hiểu thông thường về tỷ lệ bỏ lỡ.
2. Tỷ lệ bỏ lỡ toàn cầu là số lần bỏ lỡ L2 chia cho số lượng tham chiếu được thực hiện bởi bộ xử lý. Đây là biện pháp chính của chúng tôi về bộ đệm L2.
 3. Tỷ lệ bỏ lỡ solo là tỷ lệ bỏ lỡ bộ đệm L2 sẽ có nếu đó là bộ đệm duy nhất trong hệ thống. Đây là tỷ lệ bỏ lỡ được xác định theo nguyên tắc đưa vào. Nếu L2 chứa tất cả L1, thì chúng ta có thể tìm thấy số lần bỏ lỡ L2 và tốc độ tham chiếu của bộ xử lý, bỏ qua sự hiện diện của bộ đệm L1. Nguyên tắc bao gồm thông số cụ thể rằng tỷ lệ bỏ lỡ toàn cầu giống như tỷ lệ bỏ lỡ solo, cho phép chúng tôi sử dụng tỷ lệ bỏ lỡ solo để đánh giá một thiết kế.
 Dữ liệu trước (chỉ đọc sai) minh họa một số điểm nổi bật trong phân tích và thiết kế bộ đệm đa cấp:
   1. Miễn là bộ đệm L1 giống hoặc lớn hơn bộ đệm L2, phân tích theo nguyên tắc bao gồm cung cấp ước tính tốt về hành vi của bộ đệm L2. 2. Khi bộ đệm L2 lớn hơn đáng kể so với bộ đệm L1, nó có thể được coi là độc lập với các tham số L1. Tỷ lệ bỏ lỡ của nó tương ứng với tỷ lệ bỏ lỡ solo.
4.16.1 Mô hình của nhiều bộ xử lý và bộ nhớ đơn giản
 Để phát triển một mô hình bộ nhớ hữu ích, chúng ta cần một mô hình của bộ xử lý. Để phân tích, chúng tôi mô hình hóa một bộ xử lý như một nhóm gồm nhiều bộ xử lý đơn giản. Mỗi bộ xử lý đơn giản đưa ra một yêu cầu ngay khi yêu cầu trước đó được đưa ra. Trong mô hình này, chúng ta có thể thay đổi số lượng bộ xử lý và số lượng mô-đun bộ nhớ và duy trì trạng thái cân bằng yêu cầu / cung cấp dữ liệu địa chỉ. Để chuyển đổi mô hình bộ xử lý đơn thành nhiều bộ xử lý tương đương, nhà thiết kế phải xác định số lượng yêu cầu cho mô-đun bộ nhớ trên mỗi thời gian dịch vụ mô-đun, T s = T c. Một bộ xử lý đơn giản thực hiện một yêu cầu duy nhất và chờ phản hồi từ bộ nhớ. Một bộ xử lý pipelined thực hiện nhiều yêu cầu cho các bộ đệm khác nhau trước khi chờ phản hồi bộ nhớ. Có một sự tương đương gần đúng giữa n bộ xử lý đơn giản, mỗi yêu cầu một lần mỗi Ts và một bộ xử lý theo đường ống làm cho n yêu cầu mỗi Ts (Hình 4.28). Trong cuộc thảo luận sau đây, chúng tôi sử dụng hai biểu tượng để biểu thị băng thông có sẵn từ hệ thống bộ nhớ (băng thông đạt được):
   1. B. Số lượng yêu cầu được phục vụ mỗi Ts. Thỉnh thoảng, chúng tôi cũng chỉ định các đối số mà B đảm nhận, ví dụ: B (m, n) hoặc B (m). 2. Bw. Số lượng yêu cầu được phục vụ mỗi giây: Bw = B / T s.
Để dịch cái này sang các hệ thống dựa trên bộ đệm, thời gian phục vụ, Ts, là thời gian mà hệ thống bộ nhớ bận quản lý lỗi bộ nhớ cache. Số lượng mô-đun bộ nhớ, m, là số lượng bộ nhớ cache tối đa mà hệ thống bộ nhớ có thể xử lý cùng một lúc và n là tổng số yêu cầu trên mỗi T s. Đây là tổng số lần bỏ lỡ dự kiến cho mỗi bộ xử lý trên mỗi Ts nhân với số lượng bộ xử lý đưa ra yêu cầu.

Tổng hợp.
Bộ nhớ cache cung cấp cho bộ xử lý thời gian truy cập bộ nhớ nhanh hơn đáng kể so với thời gian truy cập bộ nhớ thông thường. Như vậy, bộ đệm là một thành phần quan trọng trong bộ xử lý hiện đại. Tỷ lệ miss rate bộ đệm được xác định chủ yếu bởi kích thước của bộ đệm, nhưng mọi ước tính về tỷ lệ miss rate cần phải xem xét tổ chức bộ đệm, hệ điều hành, môi trường trên hệ thống và ảnh hưởng của  I/O file. Vì thời gian truy cập bộ đệm bị giới hạn bởi kích thước, bộ nhớ cache nhiều cấp là một tính năng phổ biến của các thiết kế bộ xử lý on-die. Thiết kế bộ nhớ on-dei có vẻ tương đối dễ quản lý, đặc biệt là với sự ra đời của eDRAM, nhưng thiết kế bộ nhớ off-die là một vấn đề đặc biệt khó khăn. Mục tiêu chính của các thiết kế đó là công suất (hoặc kích thước); tuy nhiên, dung lượng bộ nhớ lớn và giới hạn pin sẽ làm thời gian truy cập chậm. Ngay cả khi các die có thể truy cập nhanh, hệ thống trên cao, Việc truyền tín hiệu bus, kiểm tra lỗi và phân phối địa chỉ, sẽ làm tăng độ trễ đáng kể. Thật vậy, các độ trễ trên không này đã tăng lên tương ứng với việc giảm thời gian chu kỳ máy. Đối mặt với thời gian truy cập bộ nhớ hàng trăm chu kỳ, nhà thiết kế có thể cung cấp băng thông bộ nhớ đầy đủ để phù hợp với tốc độ yêu cầu của bộ xử lý chỉ bằng một bộ đệm đa cấp rất lớn.
http://www.tuvantinhoc1088.com/phan-cung-pc/b-nh-trong-h-thng-may-tinh-14141


Trong hệ thống bộ nhớ đệm, thời gian cần thiết để đọc hoặc ghi dữ liệu vật lý từ bộ nhớ cache RAM chỉ chiếm một phần thời gian cần thiết để thực hiện truy cập đọc hoặc ghi bộ đệm. Đặc biệt là trong một hệ thống đa bộ xử lý, cũng cần xác định bộ đệm được cho là phải làm gì trên bất kỳ quyền truy cập nào. Xem xét, ví dụ: một bộ đệm kết hợp tập hợp là liên kết bốn chiều, được chia cho bốn ngân hàng bộ nhớ. Khi bộ xử lý thực hiện yêu cầu đọc, bộ điều khiển bộ đệm sẽ biết ngay rằng nếu dữ liệu trong bộ đệm đó phải đến từ một địa chỉ đã biết ở một trong bốn ngân hàng. Bộ điều khiển bộ đệm có thể ngay lập tức bắt đầu yêu cầu đọc cho cả bốn ngân hàng song song (không điều khiển kích hoạt đầu ra) trước khi xác định chip nào, nếu có, thực sự giữ dữ liệu. Ít nhất ba trong số các ngân hàng sẽ lấy dữ liệu vô dụng, nhưng lấy dữ liệu vô ích là vô hại (ngoài việc lãng phí một số điện). Điều quan trọng là vào thời điểm bộ điều khiển tìm ra ngân hàng nào (nếu có) giữ dữ liệu và điều khiển kích hoạt đầu ra, các bộ nhớ sẽ có thời gian để xử lý yêu cầu truy cập.

Tuy nhiên, với một yêu cầu ghi, bộ điều khiển bộ đệm thực sự không thể bắt đầu thực hiện thao tác bộ nhớ cho đến khi nó biết chip nào được cho là được ghi. Một đọc vô dụng là vô hại; người ta có thể nói "không bao giờ để tâm" một cách hiệu quả và loại bỏ dữ liệu tìm nạp sai. Một văn bản vô dụng, tuy nhiên, không thể được hoàn tác. Do đó, điều quan trọng là dữ liệu không được ghi cho đến sau khi bộ điều khiển đã tìm ra nơi ghi được cho là sẽ đi.

Nếu một người chỉ thực hiện ghi bộ nhớ, người ta có thể thực hiện chúng nhanh như đọc bằng cách sắp xếp quá trình. Trong chu kỳ n, bộ điều khiển sẽ tìm ra nơi mà bộ nhớ byte n sẽ đi, trong khi byte n-1 được ghi vào vị trí được tính trong chu kỳ trước. Tuy nhiên, rất ít tình huống liên quan đến việc ghi nhiều bộ nhớ liên tiếp mà không can thiệp vào việc đọc. Nếu ghi thực tế vào bộ nhớ xảy ra trên chu kỳ sau khi yêu cầu ghi và bộ xử lý muốn thực hiện đọc trong chu kỳ đó, thì việc đọc sẽ phải chờ.

Trong nhiều trường hợp, các bài viết bị trì hoãn thêm bởi thực tế là nhiều hệ thống không cho phép các byte bộ nhớ được ghi riêng lẻ. Một hệ thống có thể có một bus 64 bit giữa bộ nhớ cache và bộ nhớ chính và có thể yêu cầu bộ nhớ chính chỉ được ghi trong các đoạn 64 bit. Nếu mã muốn ghi một byte đơn, sẽ cần phải đọc 64 bit từ RAM, ghi một byte vào bộ đệm và sau đó sau đó ghi 64 bit trở lại RAM. Có thể bộ đệm có thể thực hiện ghi trong khi dữ liệu đang được tìm nạp từ RAM chính, và sau đó khi có sẵn dữ liệu RAM chính, chỉ sao chép 56 bit không được ghi từ bus bộ nhớ chính vào bộ đệm, nhưng logic này thêm vào phức tạp. Trong nhiều trường hợp, đơn giản hơn là chỉ cần trì hoãn ghi cho đến khi dòng bộ đệm được đọc từ RAM.

Trong các hệ thống đa bộ xử lý, mọi thứ còn phức tạp hơn nữa bởi thực tế là hai bộ xử lý có thể đọc liên tục cùng một dòng bộ đệm mà không bị nhiễu, nhưng nếu một bộ xử lý ghi một dòng bộ đệm thì bộ xử lý khác không được phép sử dụng dòng bộ đệm đó cho đến đầu tiên bộ xử lý đã ghi nó vào RAM chính và bộ xử lý thứ hai đã đọc nó hoặc bộ xử lý thứ nhất thông qua một số phương tiện khác được cung cấp dữ liệu trong đó cho bộ xử lý thứ hai. Một chuỗi các hoạt động bao gồm toàn bộ các lần đọc sẽ thực hiện nhanh hơn nhiều so với một chuỗi các hoạt động bao gồm một hỗn hợp giữa đọc và ghi (lưu ý rằng, trong nhiều trường hợp, các hoạt động dường như đòi hỏi chỉ thực sự sẽ bao gồm cả đọc và ghi ). Vấn đề không phải là quá nhiều đến nỗi bản thân ghi chậm hơn, mà là việc ghi trên một CPU có trước hoặc sau bất kỳ hoạt động nào của CPU khác sẽ yêu cầu cả hai CPU thực hiện bắt tay thêm, điều này không cần thiết nếu cả hai CPU chỉ đọc .
DRAM chậm ghi hơn đọc vì cần có thời gian để sạc hoặc xả một ô nhớ DRAM. Nhưng còn SRAM trong bộ nhớ cache L1 và L2 của bộ xử lý của tôi thì sao? Nó cũng chậm hơn để viết nhưng AFAIK, SRAM là bộ nhớ chốt dựa trên các cổng.

Dàn ý:

1.Introduction
Memory design is the key to system design. The memory system is often the most costly (in terms of area or number of die) part of the system and it largely determines the performance.
There are three factors affecting to the performance:
Processors
Interconnect (BUS, IO)
Memory.
In this chapter the interconnect, processors, and I/O are idealized so that the memory design trade-offs can be characterized. 

Memory design involves a number of considerations. The primary consideration is the application requirements:
 the operating system.
 the size.
the variability of the application processes.
This largely determines the size of memory and how the memory will be addressed: real or virtual

2.	SOC  External Memory: Flash

